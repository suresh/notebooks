{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3777564c88415aafd39c25e14bc494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c86b8b46e754b959e562c490e3614c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset banking77/default (download: 1.03 MiB, generated: 897.51 KiB, post-processed: Unknown size, total: 1.91 MiB) to /home/vscode/.cache/huggingface/datasets/banking77/default/1.1.0/aec0289529599d4572d76ab00c8944cb84f88410ad0c9e7da26189d31f62a55b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00afe0a572664699991e0b6a6f949e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/158k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e8be2b71d243d898c612e144ac10d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300dc3de22bb4090ac46d45e7aaf5044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1200f42d9bf44017876a5f63a9535d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset banking77 downloaded and prepared to /home/vscode/.cache/huggingface/datasets/banking77/default/1.1.0/aec0289529599d4572d76ab00c8944cb84f88410ad0c9e7da26189d31f62a55b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d8cd956efb440bbe0ad2ad668e971a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10003\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('banking77')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=77, names=['activate_my_card', 'age_limit', 'apple_pay_or_google_pay', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_acceptance', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_not_working', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'card_swallowed', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_card_payment', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'exchange_charge', 'exchange_rate', 'exchange_via_app', 'extra_charge_on_statement', 'failed_transfer', 'fiat_currency_support', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment?', 'supported_cards_and_currencies', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_card_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'visa_or_mastercard', 'why_verify_identity', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal'], id=None)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was I charged a higher exchange rate when I bought something abroad?\n",
      "Why didn't I receive the correct exchange rate for an item that I purchased?\n",
      "Why is the exchange rate on my card payment different than I expected?\n",
      "My rate of exchange was wrong.\n",
      "I recently bought something in foreign currency and I am unsure of the exchange rate. Is this rate applied correctly?\n"
     ]
    }
   ],
   "source": [
    "for t in dataset['train']['text'][550:555]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "train_texts = [item[\"text\"] for item in dataset[\"train\"]]\n",
    "train_labels = [item[\"label\"] for item in dataset[\"train\"]]\n",
    "\n",
    "test_texts = [item[\"text\"] for item in dataset[\"test\"]]\n",
    "test_labels = [item[\"label\"] for item in dataset[\"test\"]]\n",
    "\n",
    "label_counter = Counter(train_labels)\n",
    "label_names = dataset[\"train\"].features[\"label\"].names\n",
    "label_frequencies = {label_names[label]: [label_counter[label]] for label in label_counter}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9002\n",
      "Dev: 1001\n",
      "Test: 3080\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(train_texts, \n",
    "                                                                    train_labels, \n",
    "                                                                    test_size=0.1, \n",
    "                                                                    shuffle=True, \n",
    "                                                                    random_state=1)\n",
    "\n",
    "print(\"Train:\", len(train_texts))\n",
    "print(\"Dev:\", len(dev_texts))\n",
    "print(\"Test:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['label'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {'accuracy': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *** prajjwal1/bert-tiny ***\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97af90902a6a4f83816ba47ef9200349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/285 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfc9946ab4a4efc95f1a3610dad2311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81148e88d1a44ecd8ce8f103451406b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/vscode/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 02:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.356000</td>\n",
       "      <td>4.338256</td>\n",
       "      <td>0.022977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.301300</td>\n",
       "      <td>4.223689</td>\n",
       "      <td>0.072927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.134000</td>\n",
       "      <td>3.934121</td>\n",
       "      <td>0.292707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1500 (score: 3.9341213703155518).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *** prajjwal1/bert-mini ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmpgpx6xcwz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ae538c533d465d91b0db7438b10def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json in cache at /home/vscode/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/prajjwal1/bert-mini/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmp_axqxu3u\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c75ecac0d840bab96f2de149a949b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-mini/resolve/main/vocab.txt in cache at /home/vscode/.cache/huggingface/transformers/62f8357e13eddc9798915fddaeb0de8bb9a14deda654be17fbfd049a56dd3b5a.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/62f8357e13eddc9798915fddaeb0de8bb9a14deda654be17fbfd049a56dd3b5a.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-mini/resolve/main/vocab.txt from cache at /home/vscode/.cache/huggingface/transformers/62f8357e13eddc9798915fddaeb0de8bb9a14deda654be17fbfd049a56dd3b5a.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-mini/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-mini/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-mini/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-mini/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmpuiftgqkc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d65143ccf74b7e9a3733ca05eab7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/43.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin in cache at /home/vscode/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin from cache at /home/vscode/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
      "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vscode/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 07:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.355300</td>\n",
       "      <td>4.286866</td>\n",
       "      <td>0.032967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>3.762016</td>\n",
       "      <td>0.313686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.446100</td>\n",
       "      <td>2.991992</td>\n",
       "      <td>0.507493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1500 (score: 2.9919915199279785).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *** prajjwal1/bert-small ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmpy1q56a1x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df532a9ab70248a68cd5a9414d09c6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json in cache at /home/vscode/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/prajjwal1/bert-small/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmpdfgqwkav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d294ec8b4b84e3d94c944ece80f9fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-small/resolve/main/vocab.txt in cache at /home/vscode/.cache/huggingface/transformers/68be80309844e53b628e9d479926a991d0adf337752bb941f0188887240313b8.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/68be80309844e53b628e9d479926a991d0adf337752bb941f0188887240313b8.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-small/resolve/main/vocab.txt from cache at /home/vscode/.cache/huggingface/transformers/68be80309844e53b628e9d479926a991d0adf337752bb941f0188887240313b8.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-small/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-small/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-small/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-small/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/prajjwal1/bert-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmppvzhhj83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c08a9d621842d49668a351066f0672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/111M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-small/resolve/main/pytorch_model.bin in cache at /home/vscode/.cache/huggingface/transformers/facfdb1638fdec899406e0efd5c2c43ae4bbafcb45dd15f68df1f2378e3e70fb.59547972ec02ba39d4ea413c843f1638e8f90e118a4334ae5d626bf7524ac597\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/facfdb1638fdec899406e0efd5c2c43ae4bbafcb45dd15f68df1f2378e3e70fb.59547972ec02ba39d4ea413c843f1638e8f90e118a4334ae5d626bf7524ac597\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-small/resolve/main/pytorch_model.bin from cache at /home/vscode/.cache/huggingface/transformers/facfdb1638fdec899406e0efd5c2c43ae4bbafcb45dd15f68df1f2378e3e70fb.59547972ec02ba39d4ea413c843f1638e8f90e118a4334ae5d626bf7524ac597\n",
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-small and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vscode/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 20:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.303900</td>\n",
       "      <td>4.016153</td>\n",
       "      <td>0.157842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.436100</td>\n",
       "      <td>2.549353</td>\n",
       "      <td>0.609391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.045100</td>\n",
       "      <td>1.323907</td>\n",
       "      <td>0.802198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1500 (score: 1.3239070177078247).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *** prajjwal1/bert-medium ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "https://huggingface.co/prajjwal1/bert-medium/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmp65iqq00a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a8eafec7474a739f5dcea534310eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-medium/resolve/main/config.json in cache at /home/vscode/.cache/huggingface/transformers/288b0ee1e79a7c3fe770ab8a84ece013c573e7d226ccb5d9ffad317b3419faac.4344f82f77799c092b30b2e0d3749c809f82df14c5993e43dbbdc52f5a0d86e0\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/288b0ee1e79a7c3fe770ab8a84ece013c573e7d226ccb5d9ffad317b3419faac.4344f82f77799c092b30b2e0d3749c809f82df14c5993e43dbbdc52f5a0d86e0\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-medium/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/288b0ee1e79a7c3fe770ab8a84ece013c573e7d226ccb5d9ffad317b3419faac.4344f82f77799c092b30b2e0d3749c809f82df14c5993e43dbbdc52f5a0d86e0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/prajjwal1/bert-medium/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmpwqbee1u7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7aa4987e8147789df8377aa0d30414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-medium/resolve/main/vocab.txt in cache at /home/vscode/.cache/huggingface/transformers/8e3007f026810a2525838fbc4c6f2abd96528541e780fc424859fa801cfe70ad.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/8e3007f026810a2525838fbc4c6f2abd96528541e780fc424859fa801cfe70ad.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-medium/resolve/main/vocab.txt from cache at /home/vscode/.cache/huggingface/transformers/8e3007f026810a2525838fbc4c6f2abd96528541e780fc424859fa801cfe70ad.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-medium/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-medium/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-medium/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-medium/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-medium/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/288b0ee1e79a7c3fe770ab8a84ece013c573e7d226ccb5d9ffad317b3419faac.4344f82f77799c092b30b2e0d3749c809f82df14c5993e43dbbdc52f5a0d86e0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-medium/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/288b0ee1e79a7c3fe770ab8a84ece013c573e7d226ccb5d9ffad317b3419faac.4344f82f77799c092b30b2e0d3749c809f82df14c5993e43dbbdc52f5a0d86e0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-medium/resolve/main/config.json from cache at /home/vscode/.cache/huggingface/transformers/288b0ee1e79a7c3fe770ab8a84ece013c573e7d226ccb5d9ffad317b3419faac.4344f82f77799c092b30b2e0d3749c809f82df14c5993e43dbbdc52f5a0d86e0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/prajjwal1/bert-medium/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/vscode/.cache/huggingface/transformers/tmp8eztedc6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3053757a1e246f694d38493bed59e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/prajjwal1/bert-medium/resolve/main/pytorch_model.bin in cache at /home/vscode/.cache/huggingface/transformers/dabb6f3bc29449f038f41cb09eb1a693eee2bee3dab8afff878a2910fa73a171.b722b1c13187b9ed20e5e36ab761041218e88d502895424e3ed2516bc9693089\n",
      "creating metadata file for /home/vscode/.cache/huggingface/transformers/dabb6f3bc29449f038f41cb09eb1a693eee2bee3dab8afff878a2910fa73a171.b722b1c13187b9ed20e5e36ab761041218e88d502895424e3ed2516bc9693089\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-medium/resolve/main/pytorch_model.bin from cache at /home/vscode/.cache/huggingface/transformers/dabb6f3bc29449f038f41cb09eb1a693eee2bee3dab8afff878a2910fa73a171.b722b1c13187b9ed20e5e36ab761041218e88d502895424e3ed2516bc9693089\n",
      "Some weights of the model checkpoint at prajjwal1/bert-medium were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-medium and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vscode/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 36:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.230200</td>\n",
       "      <td>3.748593</td>\n",
       "      <td>0.291708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.087700</td>\n",
       "      <td>2.196959</td>\n",
       "      <td>0.684316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.723800</td>\n",
       "      <td>1.055814</td>\n",
       "      <td>0.864136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "/tmp/ipykernel_3315/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1500 (score: 1.0558143854141235).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 01:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model_ids = [\"prajjwal1/bert-tiny\", \"prajjwal1/bert-mini\", \n",
    "             \"prajjwal1/bert-small\", \"prajjwal1/bert-medium\",]\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for model_id in model_ids:\n",
    "    print(f\"  *** {model_id} ***\")\n",
    "\n",
    "    tokeninzer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(label_names))\n",
    "\n",
    "    train_text_encoded = tokeninzer(train_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    val_text_encoded = tokeninzer(dev_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    test_text_encoded = tokeninzer(test_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    train_dataset = ClassificationDataset(train_text_encoded, train_labels)\n",
    "    val_dataset = ClassificationDataset(val_text_encoded, dev_labels)\n",
    "    test_dataset = ClassificationDataset(test_text_encoded, test_labels)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=int(len(train_dataset)/4),\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_steps=500,\n",
    "        save_total_limit=10,\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics, train_dataset=train_dataset, eval_dataset=val_dataset)\n",
    "\n",
    "    trainer.train()\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "    accuracies.append(test_results['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          model\n",
      "prajjwal1/bert-tiny    0.262338\n",
      "prajjwal1/bert-mini    0.472403\n",
      "prajjwal1/bert-small   0.766234\n",
      "prajjwal1/bert-medium  0.817532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbb09a07bb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\"model\": accuracies}, index=model_ids)\n",
    "\n",
    "print(df)\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "ax = df.transpose().plot(kind=\"bar\", rot=0)\n",
    "ax.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.11.0-cp39-cp39-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 750.6 MB 6.7 kB/s  eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n"
     ]
    }
   ],
   "source": [
    "# ! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
