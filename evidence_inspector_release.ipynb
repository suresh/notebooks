{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresh/notebooks/blob/master/evidence_inspector_release.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gkMx2RZHSuZ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kukrishna/evidence_inspector.git"
      ],
      "metadata": {
        "id": "DDOl7CLjHfQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/evidence_inspector/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "hJNp13yZHfTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "K-DyRCmiHfVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/evidence_inspector/backend/\n",
        "!nohup python serve_seq2seq_simple.py --model-path kundank/evinspect-usb-flant5-large --port 9922  > /content/nohup_backend.out &\n",
        "\n",
        "# alternatively you can run the larger model, but would probably not fit in the free colab T4 gpu\n",
        "# !nohup python serve_seq2seq_qlora.py --model-path kundank/evinspect-usb-flanul2-qlora4bit --port 9922  > /content/nohup_backend.out &"
      ],
      "metadata": {
        "id": "ClrEyUsTHfXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following optinal command would run a backend LLM to do QA against the document in the interface. We use a falcon-7b model by default but others should work too\n",
        "# However, the free Colab GPU instance does not have enough memory to run both the fact-checking model and this LLM for QA.\n",
        "# You can use the fact-checking features of the interface even without running this. If you try to use the QA actions in the UI you would simply get the error \"QA model not reachable...\".\n",
        "\n",
        "# %cd /content/evidence_inspector/backend/\n",
        "# !nohup python serve_generic_llm.py  --model-name tiiuae/falcon-7b-instruct --port 9003 --quantize 16bit --nbeams 4  > /content/nohup_backend_llm.out &"
      ],
      "metadata": {
        "id": "KrFAdNydHfZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsCw44brHrBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the colab kernel is not directly accessible through internet, we will tunnel the traffic through an intermediary (serveo.net)\n",
        "# !! DO NOT PUT PRIVATE OR SENSITIVE DATA IN THE INTERFACE. WE TAKE NO RESPONSIBILITY FOR THE WAY THE DATA IS USED (IF ANY) BY THE INTERMEDIARY !!\n",
        "\n",
        "!nohup ssh -o StrictHostKeyChecking=no -R 80:localhost:80 serveo.net > /content/nohup_pf.out &\n",
        "!sleep 10"
      ],
      "metadata": {
        "id": "6nyqo7J9HrD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nU8hdYVbHfby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember that opening 127.0.0.1 on your browser won't show up this tool. You need to open the URL printed by this cell to access it\n",
        "\n",
        "!echo \"When you run the last cell and the server starts serving, open the URL given below in a new tab to access the system.\"\n",
        "!cat /content/nohup_pf.out | grep \"Forwarding HTTP\""
      ],
      "metadata": {
        "id": "tWRiHnCIiez4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the backend model is probably still getting downloaded at this point. This should show the progress\n",
        "!cat /content/nohup_backend.out | grep \"Downloading pytorch_model.bin\""
      ],
      "metadata": {
        "id": "hdXpkD8FjBih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before starting the frontend, the backend must download and serve the model. the frontend will wait for the backend to start.\n",
        "# if it is taking too long, you can stop this cell and run the previous cell to  see the download progress:\n",
        "\n",
        "# Also recall that you will NOT be able to access the tool using the http://127.0.0.1 URL printed by this cell.\n",
        "# Instead, to access the tool, go to the <something>.serveo.net URL that was printed by an earlier cell\n",
        "\n",
        "%cd /content/evidence_inspector/frontend\n",
        "!python job_server.py --port 80"
      ],
      "metadata": {
        "id": "moiEyCQxHfeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uv_M_yBrHyxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVMpO5GgHyzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bM73xIt5Hy1x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}